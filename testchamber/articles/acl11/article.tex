\documentclass[11pt]{article}
\usepackage{acl-hlt2011}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{6.5cm}    % Expanding the titlebox

\newcommand{\tmp}[1]{[#1]}
\newcommand{\todo}[0]{\textbf{TODO}}
\newcommand{\itemz}{\begin{itemize}}
\newcommand{\idone}{\end{itemize}}
\newcommand{\oneitem}[1]{\itemz \item #1 \idone}

\title{Automatic Translation Error Analysis}

\author{Mark Fishel \\
  Dept. of Computer Science \\
  University of Tartu, Estonia \\
  {\tt fishel@ut.ee} \\
%  \And
%  Second Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\
%  \And
%  Third Author \\
%  Affiliation / Address line 1 \\
%  Affiliation / Address line 2 \\
%  Affiliation / Address line 3 \\
%  {\tt email@domain} \\
  }

\date{}

\begin{document}
\maketitle
\begin{abstract}
\end{abstract}

\section{Introduction}

\tmp{Most efforts on MT eval concentrated on producing a single score (BLEU, NIST, METEOR, TER, SemPOS, LRscore, ad
$\inf$). While that's convenient for comparison, it is not informative.}

\tmp{manual evaluation does scoring (HTER, fluency/adequacy, rank) and some analysis (Vilar et al. 2006). \todo{}
other examples.}

\tmp{we introduce a method of automatic analysis of translation errors. It only requires the source, reference and
hypothesis translations. The whole thing is language independent, but is capable of taking additional information into
account, such as linguistic analysis (lemmatizing, PoS tagging, synonym detection), training sets or dictionaries,
etc.}

\tmp{in this work we tune our method to mimick the error taxonomy of Vilar et al.}

\tmp{Evaluated: a) in comparison with manual analysis of 4 En-Cz translations and b) by comparing the weaknesses of some
state-of-the-art statistical systems (Moses, cdec, Google) and comparing the result with what we expected (like better
order modelling in one of the systems, etc.); any languages}

\section{Related Work}

\section{Method Description}

\tmp{Word alignment between hypothesis and reference, error detection and classification, error summarization.}

\subsection{Alignment}

\tmp{The first requirement and the first step -- align the words. Whenever 1 word is aligned to several, the several are
treated as a single group (like in Tiedemann paper in COLING 2004). This automatically adds the only restriction on
alignment -- no aligning of one word to two or more \textbf{non-adjacent} words.}

\tmp{Can be any kind of alignment, by METEOR, GIZA++, or anything (\todo{} refs).}

\tmp{Aligning same-language sentences seems to be a trivial task; the only thing that makes it difficult is ambiguity:
many repeating tokens (``the'', punctuation, \dots), synonyms, same-lemma-wrong-form examples, etc.}

\tmp{Here -- HMM-model-like alignment, hyp words are the observed variables, ref words -- hidden variables. Instead of
learning the emission/transition probabilities, these are hand-crafted. Therefore the resulting model should have the
advantages of HMM alignment without the necessity to learn the models (good for applying to a small set of
translations).}

\tmp{Emission probability depends on the number of
the same words in the hypothesis; for a hyp word $w^{(h)}_i$ that occurs only once
\[
	p_{emit}(w^{(h)}_i | w^{(r)}_{a_i}) = [w^{(h)}_i = w^{(r)}_{a_i}];
\]
for other words (occurring many times)
\[
	p_{emit}(w^{(h)}_i | \emptyset) = \varepsilon,
\]
\[
	p_{emit}(w^{(h)}_i|w^{(r)}_{a_i}) = \frac{(1 - \varepsilon) \cdot [w^{(h)}_i = w^{(r)}_{a_i}]}{|\{w: w \in \mbox{hyp}, w = w^{(h)}_i \}|}.
\]
This allows repeating words to remain unaligned to make way for other, potentially better alignments of the same word,
while always aligning unique words to their counterpart.}

\tmp{The transition probabilities stimulate aligning the current pair in parallel to the previously produced pair by
penalizing the distance between the previous and the current reference word:
\[
	p_{trans}(w^{(r)}_{a_i} | w^{(r)}_{a_{i\_}}) \sim \exp(-b \cdot |a_i - a_{i\_} - 1|),
\]
where $a_{i\_}$ is the index of the latest non-NULL alignment in the alignment $\mathbf{a}$.}

\tmp{We do alignment based on lemmas, in order to detect same-lemma-wrong-form translations; alternative is detecting
synonyms (synosets?) and using them for alignment to support detecting synonym translations.}

\tmp{\todo{} -- describe here or in rel. work sct, how METEOR and TER do alignment, and whether that's better or worse
than our method.}

\subsection{Detecting Lexical Errors}

\tmp{Using the alignment we detect and classify translation errors (correspondence errors):}

\itemz
	\item unaligned words in the reference = missing words
		\oneitem{can be further classified into punctuation and content/filler words, using PoS-tagging}
	\item unaligned words in the hypothesis = extra words
	\itemz
		\item also further classified (punctuation, content/filler word)
		\item if present in the source sentence -- then it's an untranslated word
	\idone
	\item aligned but different word form = same-lemma-wrong-form translation
\idone

\subsection{Detecting Order Errors}

\tmp{The aligned words and word groups are in a 1-to-1 correspondence; this can be used to calculate Hamming
distance, Kendall's $\tau$ distance, Ulam's distance (Birch,Blunsom,Osborne@MT Journal, 2010), Spearman's rank correlation
coefficient, etc.}

\tmp{Here we want to detect misplaced words and word groups. For that we do a breadth-first search for fixing the order
in the aligned hypothesis words. The weighed DAG is created like this:}

\itemz
	\item one node per every permutation
	\item there's an arc iff the target node permutation differs from the source permutation by two adjacent symbols,
		whereas the relative order of the two symbols is wrong in the source and correct in the target
	\item the arc weight is generally equal to 1; in order to enable block shifts, the weight is 0 only if the current
		arc continues shifting a symbol to the right or to the left
\idone

\tmp{\todo{}: currently missing, but have to group adjacent word alignments into word groups -- this will make the
unscrambling faster, and the groups can be treated as phrazes for order error detection; Ondrej, Dan -- does the latter make sense?}

\subsection{Summarization}

\tmp{Can be done on many levels:}

\itemz
	\item no summarization -- inspecting translation errors in every sentence = Addicter! :)
	\item summarization รก la (Vilar et al. 2006) -- ratio of missing/untranslated/extra/wrong-form/misplaced words
	\item linear combination of the error type ratios -- score!
\idone

\section{Experiments and Results}

\todo{}:

\itemz
	\item apply Mor\v{c}e to the 4 En-Cz translations from WMT09
	\item apply the introduced analysis to it
	\item compare results to Ondrej's MT Journal article analysis
\idone

\begin{figure*}
\input{example.txt}
\caption{Example of analysis, done for Google's Ee-En translation}
\end{figure*}

\section{Conclusions}

\end{document}
